# agents/analytics_agent.py
import sqlite3
import os
import json
import uuid
from langchain.prompts import PromptTemplate
from langchain_google_genai import ChatGoogleGenerativeAI


# ==========================
# Cr√©ation de la base de donn√©es pour les analytics
# ==========================
def init_analytics_db():
    """Initialise la base de donn√©es SQLite pour l'analytics."""
    db_path = "data/analytics/analytics.db"
    os.makedirs(os.path.dirname(db_path), exist_ok=True)
    
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()
    
    # V√©rifier si la table existe d√©j√†
    cursor.execute("""
        SELECT name FROM sqlite_master 
        WHERE type='table' AND name='chat_analytics'
    """)
    table_exists = cursor.fetchone()
    
    if table_exists:
        print("‚úÖ Base de donn√©es analytics d√©j√† initialis√©e.")
    else:
        print("üî® Cr√©ation de la table chat_analytics...")
        cursor.execute("""
        CREATE TABLE IF NOT EXISTS chat_analytics (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            chat_id TEXT,
            intent TEXT,
            satisfaction_score REAL,
            chat_duration REAL,
            improvement_suggestion TEXT,
            timestamp DATETIME DEFAULT CURRENT_TIMESTAMP
        )
        """)
        conn.commit()
        print("‚úÖ Table chat_analytics cr√©√©e avec succ√®s.")
    
    conn.close()


# ==========================
# Analyse LLM avec historique
# ==========================
def analyze_conversation(
    user_message: str,
    agent_response: str,
    chat_history: str,
    duration: float
) -> dict:
    """
    Analyse une conversation compl√®te avec le LLM.
    
    Args:
        user_message: Dernier message du client
        agent_response: Derni√®re r√©ponse de l'agent
        chat_history: Historique complet de la conversation
        duration: Dur√©e totale de la conversation
        
    Returns:
        dict: Contient chat_id, theme, satisfaction_score, remarque
    """
    chat_id = str(uuid.uuid4())

    llm_analyse = ChatGoogleGenerativeAI(
        model="gemini-2.5-flash",
        temperature=0.2,
        api_key=os.getenv("GEMINI_API_KEY")
    )

    # Prompt prenant en compte l'historique complet
    analyse_prompt = PromptTemplate(
        input_variables=["chat_history", "user_message", "agent_response"],
        template="""
    Tu es un analyste conversationnel expert pour le support client Fnac.
    Analyse cette conversation compl√®te client-agent.

    Historique complet :
    {chat_history}

    Dernier message client :
    {user_message}

    Derni√®re r√©ponse agent :
    {agent_response}

    Pour chaque conversation, fournis un JSON avec :

    1Ô∏è‚É£ theme : le th√®me principal de la conversation (ex: commande, retour, produit, paiement, assistance technique)
    2Ô∏è‚É£ satisfaction_score : un nombre entre 0 et 1 repr√©sentant la satisfaction globale du client
    3Ô∏è‚É£ remarque : un court r√©sum√© des points importants ou frustrations √©ventuelles
    4Ô∏è‚É£ improvement_suggestion : (OPTIONNEL - seulement si satisfaction_score < 0.6) UNE suggestion concr√®te pour am√©liorer la r√©ponse
    
    - Tous les guillemets doubles " dans le texte doivent √™tre √©chapp√©s avec un backslash \"
    - R√©pond strictement en JSON sous ce format :

    {{
    "theme": "retour",
    "satisfaction_score": 0.8,
    "remarque": "Le client voulait retourner un produit, agent a r√©pondu clairement",
    "improvement_suggestion": null
    }}
    
    ou si satisfaction < 0.6 :

    {{
    "theme": "retour",
    "satisfaction_score": 0.45,
    "remarque": "Le client √©tait frustr√© par le manque de clart√©",
    "improvement_suggestion": "Proposer des d√©lais sp√©cifiques au lieu de r√©ponses vagues"
    }}
    
    Ne pas utiliser de balises Markdown, renvoie uniquement le JSON pur.
    """
    )
    prompt_text = analyse_prompt.format(
        chat_history=chat_history,
        user_message=user_message,
        agent_response=agent_response
    )

    try:
        result = llm_analyse.invoke(prompt_text).content
        data = json.loads(result)
        intent = data.get("theme", "autre")
        satisfaction = float(data.get("satisfaction_score", 0.5))
        remarque = data.get("remarque", "")
        improvement_suggestion = data.get("improvement_suggestion")  # Peut √™tre None

    except Exception as e:
        print(f"‚ö†Ô∏è Erreur lors de l'analyse LLM: {e}")
        intent = "autre"
        satisfaction = 0.5
        remarque = ""
        improvement_suggestion = None

    return {
        "chat_id": chat_id,
        "theme": intent,
        "satisfaction_score": satisfaction,
        "remarque": remarque,
        "improvement_suggestion": improvement_suggestion,
        "duration": duration
    }


def store_analytics(analysis_result: dict) -> bool:
    """
    Stocke les r√©sultats d'analyse dans la base de donn√©es.
    
    Args:
        analysis_result: Dict contenant les r√©sultats de analyze_conversation()
        
    Returns:
        bool: True si succ√®s, False sinon
    """
    try:
        conn = sqlite3.connect("data/analytics/analytics.db")
        cursor = conn.cursor()
        cursor.execute("""
            INSERT INTO chat_analytics (chat_id, intent, satisfaction_score, chat_duration, improvement_suggestion)
            VALUES (?, ?, ?, ?, ?)
        """, (
            analysis_result["chat_id"],
            analysis_result["theme"],
            analysis_result["satisfaction_score"],
            analysis_result["duration"],
            analysis_result.get("improvement_suggestion")
        ))
        conn.commit()
        conn.close()
        return True
    except Exception as e:
        print(f"‚ùå Erreur lors du stockage en base: {e}")
        return False


def analytics_agent(
    user_message: str,
    agent_response: str,
    chat_history: str,
    duration: float
) -> dict:
    """
    Combine analyse + stockage en une seule fonction.
    Appelle le manager si satisfaction < 0.6 pour g√©n√©rer les guidelines d'am√©lioration.
    
    Args:
        user_message: Dernier message du client
        agent_response: Derni√®re r√©ponse de l'agent
        chat_history: Historique complet
        duration: Dur√©e de la conversation
        
    Returns:
        dict: R√©sultats d'analyse
    """
    from agents.manager_agent import manager_update
    
    analysis = analyze_conversation(user_message, agent_response, chat_history, duration)
    store_analytics(analysis)
    
    # Affichage
    msg = f"‚úÖ Analyse stock√©e - Th√®me: {analysis['theme']}, Satisfaction: {analysis['satisfaction_score']}"
    if analysis.get("improvement_suggestion"):
        msg += f"\nüí° Suggestion: {analysis['improvement_suggestion']}"
    
    print(msg)
    
    # üîÑ Si satisfaction faible, appeler le manager pour mettre √† jour les guidelines
    if analysis['satisfaction_score'] < 0.6:
        print("üìû Appel du Manager pour mise √† jour des guidelines...")
        manager_update()
    
    return analysis
